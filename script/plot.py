#!/usr/bin/env python3
"""
Multi-Metric Memory Simulator Results Visualizer

This script creates visualizations from timestamp-specific CSV files generated by the 
memory simulator results gatherer. It can plot multiple metrics in separate graphs
and supports comparing results across multiple timestamp experiments.
"""

import os
import argparse
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from pathlib import Path
import glob
import re
import adjustText

# Define some color palettes for different configuration groups
CONFIG_COLORS = plt.cm.tab20(np.linspace(0, 1, 20))

def find_timestamp_csvs(base_dir):
    """
    Find all timestamp-specific CSV files in the given directory
    
    Args:
        base_dir: Directory containing timestamp CSV files
        
    Returns:
        A dictionary mapping timestamp labels to file paths
    """
    timestamp_files = {}
    
    # Convert to Path object
    base_path = Path(base_dir)
    
    # Look for CSV files with the pattern experiment_YYYYMMDD_HHMMSS.csv
    csv_files = list(base_path.glob("experiment_*.csv"))
    
    for csv_file in csv_files:
        # Extract timestamp from filename
        match = re.search(r'experiment_(\d{8}_\d{6})\.csv', csv_file.name)
        if match:
            timestamp = match.group(1)
            # Format timestamp for better display
            formatted_timestamp = f"{timestamp[0:4]}-{timestamp[4:6]}-{timestamp[6:8]} {timestamp[9:11]}:{timestamp[11:13]}:{timestamp[13:15]}"
            timestamp_files[formatted_timestamp] = csv_file
    
    return timestamp_files

def list_experiment_names(timestamp_files):
    """
    List experiment names for each timestamp file
    
    Args:
        timestamp_files: Dictionary mapping timestamps to file paths
        
    Returns:
        A dictionary mapping timestamps to experiment names
    """
    experiment_names = {}
    
    for timestamp, file_path in timestamp_files.items():
        try:
            # Read just a few rows to extract experiment name
            df = pd.read_csv(file_path, nrows=1)
            if 'experiment_name' in df.columns:
                experiment_names[timestamp] = df['experiment_name'].iloc[0]
            else:
                experiment_names[timestamp] = "Unknown"
        except Exception as e:
            print(f"Error reading experiment name from {file_path}: {e}")
            experiment_names[timestamp] = "Error"
    
    return experiment_names

def load_data(csv_file):
    """
    Load data from a CSV file into a pandas DataFrame
    
    Args:
        csv_file: Path to the CSV file
        
    Returns:
        A pandas DataFrame containing the data
    """
    try:
        df = pd.read_csv(csv_file)
        print(f"Loaded {len(df)} rows from {csv_file}")
        return df
    except Exception as e:
        print(f"Error loading data from {csv_file}: {e}")
        return pd.DataFrame()

def get_unique_values(df, columns):
    """
    Get unique values for specified columns
    
    Args:
        df: pandas DataFrame
        columns: List of column names
        
    Returns:
        A dictionary mapping column names to lists of unique values
    """
    unique_values = {}
    for column in columns:
        if column in df.columns:
            values = sorted(df[column].dropna().unique().tolist())
            unique_values[column] = values
    return unique_values

def filter_data(df, selected_config_ids):
    """
    Filter DataFrame based on selected configuration IDs
    
    Args:
        df: pandas DataFrame
        selected_config_ids: List of selected configuration identifiers
        
    Returns:
        A filtered pandas DataFrame containing only the selected configurations
    """
    if not selected_config_ids:
        return df.copy()
    
    # Create a complete configuration ID for each row
    pagetable_cols = ['pgd_size', 'pud_size', 'pmd_size', 'pte_size']
    pwc_cols = ['pgd_pwc_entries', 'pud_pwc_entries', 'pmd_pwc_entries']
    toc_cols = ['toc_enabled', 'toc_size']
    all_config_cols = pagetable_cols + pwc_cols + toc_cols
    
    # Only use columns that exist in the dataframe
    config_cols = [col for col in all_config_cols if col in df.columns]
    
    # Create a temporary DataFrame with configuration IDs
    result_df = df.copy()
    
    # We need to create the same config_id as was used in the selection process
    # This will create consistent identifiers for matching
    result_df['_config_id'] = result_df.apply(
        lambda row: generate_config_id(row, config_cols), 
        axis=1
    )
    
    # Filter to include only selected configuration IDs
    filtered_df = result_df[result_df['_config_id'].isin(selected_config_ids)]
    
    # Remove temporary config_id column
    if '_config_id' in filtered_df.columns:
        filtered_df = filtered_df.drop('_config_id', axis=1)
    
    return filtered_df

def generate_config_id(row, config_cols):
    """
    Generate a unique identifier for a complete configuration
    
    Args:
        row: pandas Series (a row from the DataFrame)
        config_cols: List of configuration columns
        
    Returns:
        A string identifier for the configuration
    """
    # Define configuration groups
    pagetable_cols = ['pgd_size', 'pud_size', 'pmd_size', 'pte_size']
    pwc_cols = ['pgd_pwc_entries', 'pud_pwc_entries', 'pmd_pwc_entries']
    toc_cols = ['toc_enabled', 'toc_size']
    
    # Filter to only columns that exist in the row
    pagetable_cols = [col for col in pagetable_cols if col in config_cols]
    pwc_cols = [col for col in pwc_cols if col in config_cols]
    toc_cols = [col for col in toc_cols if col in config_cols]
    
    # Create parts for each configuration group
    pagetable_part = "|".join([f"{col}={row[col]}" for col in pagetable_cols if col in row])
    pwc_part = "|".join([f"{col}={row[col]}" for col in pwc_cols if col in row])
    
    # Handle TOC specially
    toc_part = ""
    if 'toc_enabled' in toc_cols and 'toc_enabled' in row:
        toc_enabled = row['toc_enabled']
        if isinstance(toc_enabled, str):
            toc_enabled = toc_enabled.lower() == 'true'
        toc_part += f"toc_enabled={toc_enabled}"
    
    if 'toc_size' in toc_cols and 'toc_size' in row:
        if toc_part:
            toc_part += "|"
        toc_part += f"toc_size={row['toc_size']}"
    
    # Combine all parts into a single identifier
    config_parts = []
    if pagetable_part:
        config_parts.append(f"PT[{pagetable_part}]")
    if pwc_part:
        config_parts.append(f"PWC[{pwc_part}]")
    if toc_part:
        config_parts.append(f"TOC[{toc_part}]")
    
    return "::".join(config_parts)

def get_config_label(row, config_columns):
    """
    Create a label for a configuration based on column values,
    grouping them by configuration type for better readability
    
    Args:
        row: pandas Series (a row from the DataFrame)
        config_columns: List of column names to include in the label
        
    Returns:
        A string label for the configuration
    """
    # Define configuration groups
    pagetable_cols = ['pgd_size', 'pud_size', 'pmd_size', 'pte_size']
    pwc_cols = ['pgd_pwc_entries', 'pud_pwc_entries', 'pmd_pwc_entries']
    toc_cols = ['toc_enabled', 'toc_size']
    
    # Initialize part collectors for each group
    pagetable_parts = []
    pwc_parts = []
    toc_parts = []
    other_parts = []
    
    # Process each column based on its group
    for col in config_columns:
        if col in row and not pd.isna(row[col]):
            # Page table configuration
            if col in pagetable_cols:
                col_label = col.replace('_size', '')
                pagetable_parts.append(f"{col_label}={row[col]}")
            
            # PWC configuration
            elif col in pwc_cols:
                col_label = col.replace('_pwc_entries', '')
                pwc_parts.append(f"{col_label}_pwc={row[col]}")
            
            # TOC configuration
            elif col in toc_cols:
                if col == 'toc_enabled':
                    # Handle toc_enabled specially
                    is_enabled = False
                    if isinstance(row[col], bool):
                        is_enabled = row[col]
                    else:
                        is_enabled = str(row[col]).lower() == 'true'
                    
                    toc_parts.append('TOC' if is_enabled else 'noTOC')
                else:
                    if any(part.startswith('TOC') for part in toc_parts):
                        # Only include toc_size if TOC is enabled
                        toc_parts.append(f"TOC{col.replace('toc_', '')}={row[col]}")
            
            # Other configuration parameters
            else:
                other_parts.append(f"{col}={row[col]}")
    
    # Combine parts from each group
    parts = []
    
    # Add page table configuration if present
    if pagetable_parts:
        parts.append("PT[" + ", ".join(pagetable_parts) + "]")
    
    # Add PWC configuration if present
    if pwc_parts:
        parts.append("PWC[" + ", ".join(pwc_parts) + "]")
    
    # Add TOC configuration if present
    if toc_parts:
        parts.append(", ".join(toc_parts))
    
    # Add other configuration parameters
    if other_parts:
        parts.append(", ".join(other_parts))
    
    return " | ".join(parts)

def sort_configs(df, config_columns):
    """
    Sort configurations based on specified keys.
    Now considers configuration groups for more logical sorting.
    
    Args:
        df: pandas DataFrame
        config_columns: List of column names to define the sort order
        
    Returns:
        A sorted pandas DataFrame
    """
    # Define sort priority groups
    pagetable_sort_keys = ['pgd_size', 'pud_size', 'pmd_size', 'pte_size']
    pwc_sort_keys = ['pgd_pwc_entries', 'pud_pwc_entries', 'pmd_pwc_entries']
    toc_sort_keys = ['toc_enabled', 'toc_size']
    
    # Combine sort keys in priority order
    sort_keys = pagetable_sort_keys + pwc_sort_keys + toc_sort_keys
    
    # Ensure sort_keys are in the DataFrame
    sort_keys = [key for key in sort_keys if key in df.columns]
    
    # If no valid sort keys, return the original DataFrame
    if not sort_keys:
        return df
    
    return df.sort_values(by=sort_keys)

def create_bar_plot(df, x_column, y_column, config_columns, title=None, output_file=None, 
                   sort_bars=False, fig_size=(14, 8), timestamp_label=None):
    """
    Create a bar plot with different configurations as bars
    
    Args:
        df: pandas DataFrame
        x_column: Column to use for x-axis (typically 'workload')
        y_column: Column to use for y-axis (the statistic to visualize)
        config_columns: Columns that define a configuration
        title: Plot title
        output_file: Path to save the plot
        sort_bars: Whether to sort bars by y-value
        fig_size: Figure size (width, height) in inches
        timestamp_label: Optional label to identify the timestamp
    """
    if df.empty:
        print("No data to plot")
        return
    
    # Check if columns exist
    if x_column not in df.columns:
        print(f"Error: Column {x_column} not found in data")
        return
    if y_column not in df.columns:
        print(f"Error: Column {y_column} not found in data")
        return
    
    # Add timestamp column if provided
    if timestamp_label:
        if 'timestamp' not in df.columns:
            df['timestamp'] = timestamp_label
    

    # Create a configuration ID by combining specified columns
    df['config_id'] = df.apply(lambda row: get_config_label(row, config_columns), axis=1)
    
    # Group by x_column and config_id, and calculate the mean of y_column
    if timestamp_label and 'timestamp' in df.columns:
        grouped = df.groupby([x_column, 'config_id', 'timestamp'])[y_column].mean().reset_index()
    else:
        grouped = df.groupby([x_column, 'config_id'])[y_column].mean().reset_index()
    
    # Get unique x values and configurations
    x_values = sorted(df[x_column].unique())
    
    # Sort configurations based on specified keys
    df = sort_configs(df, config_columns)
    
    configs = (df['config_id'].unique())

    # The number of bars for each x value
    n_configs = len(configs)
    
    # The width of each bar
    bar_width = 0.8 / n_configs
    
    # Set up the figure and axis with more space at the top for the legend
    plt.figure(figsize=fig_size)
    ax = plt.subplot(111)
    # Adjust the top margin to make room for the legend
    plt.subplots_adjust(top=0.85)
    
    # Plotting
    all_text = []
    for i, config in enumerate(configs):
        # Get data for this configuration
        config_data = grouped[grouped['config_id'] == config]
        
        # Sort config_data by y_column if requested
        if sort_bars:
            config_data = config_data.sort_values(by=y_column)
        
        # Calculate x positions for this configuration's bars
        indices = np.arange(len(x_values))
        positions = indices - 0.4 + (i + 0.5) * bar_width
        
        # Values to plot
        values = []
        for x_val in x_values:
            val_row = config_data[config_data[x_column] == x_val]
            if not val_row.empty:
                values.append(val_row[y_column].values[0])
            else:
                values.append(0)
        
        # Include timestamp in label if multiple timestamps are being plotted
        if timestamp_label and 'timestamp' in df.columns:
            label = f"{config} - {timestamp_label}"
        else:
            label = config
            
        # Plot the bars
        bars = ax.bar(positions, values, bar_width, label=label, color=CONFIG_COLORS[i % len(CONFIG_COLORS)])
        
        # Add data labels to bars
        for bar, value in zip(bars, values):
            # Format value based on magnitude
            if abs(value) < 0.01:
                value_text = f"{value:.3f}"
            elif abs(value) < 1:
                value_text = f"{value:.2f}"
            elif abs(value) < 100:
                value_text = f"{value:.1f}"
            else:
                if not isinstance(value, (int, float)) or not value.is_integer():
                    value_text = f"{value:.1f}"
                else:
                    value_text = f"{int(value)}"
                
            # Position the text above the bar
            height = bar.get_height()
            all_text.append(ax.text(bar.get_x() + bar.get_width()/2., height + 0.01 * max(values),
                    value_text, ha='center', va='bottom', rotation=45, fontsize=8))
    
    # Adjust text positions to avoid overlap
    # adjustText.adjust_text(all_text, arrowprops=dict(arrowstyle="-", color='grey'), 
    #                        only_move={'points': 'y', 'text': 'y'})
    # Add labels and title
    ax.set_xlabel(x_column.replace('_', ' ').title())
    ax.set_ylabel(y_column.replace('_', ' ').title())
    if title:
        plt.title(title)
    else:
        plt.title(f'{y_column.replace("_", " ").title()} by {x_column.replace("_", " ").title()}')
    
    # Set y-axis limits for percentage metrics
    if any(term in y_column.lower() for term in ['percentage', 'efficiency', 'hit_rate', 'ratio']):
        ax.set_ylim(0, max(120, max(values if values else [0]) * 1.2))  # Increase upper limit to make room for labels
    else:
        if values:
            ax.set_ylim(0, max(values) * 1.2)  # Increase upper limit to make room for labels
        else:
            ax.set_ylim(0, 100)  # Default if no values
    
    # Set x-tick labels
    ax.set_xticks(indices)
    ax.set_xticklabels(x_values, rotation=45, ha='right')
    
    # Add a legend below the x-axis
    ncols = min(1, n_configs)
    ax.legend(loc='upper center', ncol=ncols, fontsize='small', bbox_to_anchor=(0.5, -0.15))
    
    # Adjust layout
    plt.tight_layout()
    
    # Save if output_file is specified
    if output_file:
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"Saved plot to {output_file}")
    
    # Show the plot
    plt.show()

def create_grouped_bar_plot(df, x_column, y_column, group_column, config_columns, 
                          title=None, output_file=None, fig_size=(14, 8), timestamp_label=None):
    """
    Create a grouped bar plot with different configurations as groups
    
    Args:
        df: pandas DataFrame
        x_column: Column to use for x-axis (typically 'workload')
        y_column: Column to use for y-axis (the statistic to visualize)
        group_column: Column to use for grouping (e.g., 'toc_enabled')
        config_columns: Columns that define a configuration
        title: Plot title
        output_file: Path to save the plot
        fig_size: Figure size (width, height) in inches
        timestamp_label: Optional label to identify the timestamp
    """
    if df.empty:
        print("No data to plot")
        return
    
    # Check if columns exist
    if x_column not in df.columns:
        print(f"Error: Column {x_column} not found in data")
        return
    if y_column not in df.columns:
        print(f"Error: Column {y_column} not found in data")
        return
    if group_column not in df.columns:
        print(f"Error: Column {group_column} not found in data")
        return
    
    # Add timestamp column if provided
    if timestamp_label:
        if 'timestamp' not in df.columns:
            df['timestamp'] = timestamp_label
    
    # Create a configuration ID by combining specified columns (excluding the group column)
    config_cols = [col for col in config_columns if col != group_column]
    df['config_id'] = df.apply(lambda row: get_config_label(row, config_cols), axis=1)
    
    # Group by x_column, group_column and config_id, and calculate the mean of y_column
    if timestamp_label and 'timestamp' in df.columns:
        grouped = df.groupby([x_column, group_column, 'config_id', 'timestamp'])[y_column].mean().reset_index()
    else:
        grouped = df.groupby([x_column, group_column, 'config_id'])[y_column].mean().reset_index()
    
    # Get unique values
    x_values = sorted(df[x_column].unique())
    group_values = sorted(df[group_column].unique())
    
    # Sort configurations based on specified keys
    df = sort_configs(df, config_columns)

    # Extract unique configurations after sorting
    configs = sorted(df['config_id'].unique())

    # The number of groups
    n_groups = len(group_values)
    
    # The width of each group
    group_width = 0.8 / len(configs)
    
    # Set up the figure and axis with more space at the top for the legend
    plt.figure(figsize=fig_size)
    ax = plt.subplot(111)
    # Adjust the top margin to make room for the legend
    plt.subplots_adjust(top=0.85)
    
    # Plotting
    for i, config in enumerate(configs):
        # Get data for this configuration
        config_data = grouped[grouped['config_id'] == config]
        
        # Calculate x positions for this configuration's groups
        indices = np.arange(len(x_values))
        
        # Plot each group
        for j, group_val in enumerate(group_values):
            # Get data for this group
            group_data = config_data[config_data[group_column] == group_val]
            
            # Calculate positions for this group's bars
            positions = indices - 0.4 + (i * n_groups + j + 0.5) * (group_width / n_groups)
            
            # Values to plot
            values = []
            for x_val in x_values:
                val_row = group_data[group_data[x_column] == x_val]
                if not val_row.empty:
                    values.append(val_row[y_column].values[0])
                else:
                    values.append(0)
            
            # Label for this group
            if group_column == 'toc_enabled':
                group_label = 'TOC Enabled' if str(group_val).lower() == 'true' else 'TOC Disabled'
            else:
                group_label = f"{group_column}={group_val}"
            
            # Include timestamp in label if multiple timestamps are being plotted
            if timestamp_label and 'timestamp' in df.columns:
                bar_label = f"{config}, {group_label} - {timestamp_label}"
            else:
                bar_label = f"{config}, {group_label}"
            
            # Plot the bars
            bars = ax.bar(positions, values, group_width / n_groups, label=bar_label, 
                  color=CONFIG_COLORS[(i * n_groups + j) % len(CONFIG_COLORS)])
            
            # Add data labels to bars
            for bar, value in zip(bars, values):
                # Format value based on magnitude
                if value == 0:
                    continue  # Skip zero values
                elif abs(value) < 0.01:
                    value_text = f"{value:.3f}"
                elif abs(value) < 1:
                    value_text = f"{value:.2f}"
                elif abs(value) < 100:
                    value_text = f"{value:.1f}"
                else:
                    value_text = f"{int(value)}"
                    
                # Position the text above the bar
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height + 0.01 * max(values if values else [0]),
                        value_text, ha='center', va='bottom', rotation=45, fontsize=8)
    
    # Add labels and title
    ax.set_xlabel(x_column.replace('_', ' ').title())
    ax.set_ylabel(y_column.replace('_', ' ').title())
    if title:
        plt.title(title)
    else:
        plt.title(f'{y_column.replace("_", " ").title()} by {x_column.replace("_", " ").title()} and {group_column.replace("_", " ").title()}')
    
    # Set y-axis limits for percentage metrics
    if any(term in y_column.lower() for term in ['percentage', 'efficiency', 'hit_rate', 'ratio']):
        ax.set_ylim(0, 110)  # Set to slightly above 100% to make room for labels
    else:
        max_values = [val for vals in [list(group_data[y_column]) for _, group_data in grouped.groupby([group_column, 'config_id'])] for val in vals]
        if max_values:
            ax.set_ylim(0, max(max_values) * 1.2)  # Increase upper limit to make room for labels
        else:
            ax.set_ylim(0, 100)  # Default if no values
    
    # Set x-tick labels
    ax.set_xticks(indices)
    ax.set_xticklabels(x_values, rotation=45, ha='right')
    
    # Add a legend below the x-axis
    ncols = min(3, len(configs) * n_groups)
    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=ncols, fontsize='small')
    
    # Adjust layout
    plt.tight_layout()
    
    # Save if output_file is specified
    if output_file:
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"Saved plot to {output_file}")
    
    # Show the plot
    plt.show()

def create_heatmap(df, x_column, y_column, value_column, title=None, output_file=None, 
                 fig_size=(14, 10), timestamp_label=None):
    """
    Create a heatmap visualization
    
    Args:
        df: pandas DataFrame
        x_column: Column to use for x-axis
        y_column: Column to use for y-axis
        value_column: Column to use for cell values
        title: Plot title
        output_file: Path to save the plot
        fig_size: Figure size (width, height) in inches
        timestamp_label: Optional label to identify the timestamp
    """
    if df.empty:
        print("No data to plot")
        return
    
    # Check if columns exist
    if x_column not in df.columns:
        print(f"Error: Column {x_column} not found in data")
        return
    if y_column not in df.columns:
        print(f"Error: Column {y_column} not found in data")
        return
    if value_column not in df.columns:
        print(f"Error: Column {value_column} not found in data")
        return
    
    # Add timestamp column if provided
    if timestamp_label:
        if 'timestamp' not in df.columns:
            df['timestamp'] = timestamp_label
            
            # Include timestamp in title
            if title:
                title = f"{title} - {timestamp_label}"
            else:
                title = f"{value_column.replace('_', ' ').title()} by {x_column.replace('_', ' ').title()} and {y_column.replace('_', ' ').title()} - {timestamp_label}"
    
    # Group by x and y columns and calculate the mean of the value column
    pivoted = df.pivot_table(index=y_column, columns=x_column, values=value_column, aggfunc='mean')
    
    # Set up the figure
    plt.figure(figsize=fig_size)
    
    # Check if the value column is a percentage
    is_percentage = any(term in value_column.lower() for term in ['percentage', 'efficiency', 'hit_rate', 'ratio'])
    
    # Create the heatmap with appropriate vmin/vmax for percentages
    if is_percentage:
        heatmap = sns.heatmap(pivoted, annot=True, cmap='YlGnBu', fmt='.2f', linewidths=0.5, vmin=0, vmax=100)
    else:
        heatmap = sns.heatmap(pivoted, annot=True, cmap='YlGnBu', fmt='.2f', linewidths=0.5)
    
    # Add title
    if title:
        plt.title(title)
    else:
        plt.title(f'{value_column.replace("_", " ").title()} by {x_column.replace("_", " ").title()} and {y_column.replace("_", " ").title()}')
    
    # Adjust layout
    plt.tight_layout()
    
    # Save if output_file is specified
    if output_file:
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"Saved plot to {output_file}")
    
    # Show the plot
    plt.show()

def combine_dataframes(dataframes, timestamps):
    """
    Combine multiple dataframes from different timestamps
    
    Args:
        dataframes: List of pandas DataFrames
        timestamps: List of timestamp labels
        
    Returns:
        A single pandas DataFrame with a 'timestamp' column
    """
    combined_df = pd.DataFrame()
    
    for df, timestamp in zip(dataframes, timestamps):
        if not df.empty:
            # Add timestamp column
            df_copy = df.copy()
            df_copy['timestamp'] = timestamp
            
            # Append to combined DataFrame
            combined_df = pd.concat([combined_df, df_copy], ignore_index=True)
    
    return combined_df

def create_comparison_plot(combined_df, x_column, y_column, config_columns, 
                          plot_type='bar', group_column=None, title=None, 
                          output_file=None, sort_bars=False, fig_size=(14, 8)):
    """
    Create a plot comparing data from multiple timestamps
    
    Args:
        combined_df: pandas DataFrame with data from multiple timestamps
        x_column: Column to use for x-axis
        y_column: Column to use for y-axis
        config_columns: Columns that define a configuration
        plot_type: Type of plot ('bar', 'grouped', 'heatmap')
        group_column: Column to use for grouping (for grouped bar plots)
        title: Plot title
        output_file: Path to save the plot
        sort_bars: Whether to sort bars by y-value
        fig_size: Figure size (width, height) in inches
    """
    if combined_df.empty:
        print("No data to plot")
        return
    
    # Check if required columns exist
    if x_column not in combined_df.columns:
        print(f"Error: Column {x_column} not found in data")
        return
    if y_column not in combined_df.columns:
        print(f"Error: Column {y_column} not found in data")
        return
    if 'timestamp' not in combined_df.columns:
        print("Error: No timestamp column found in combined data")
        return
    
    # Create a configuration ID by combining specified columns
    combined_df['config_id'] = combined_df.apply(lambda row: get_config_label(row, config_columns), axis=1)
    
    # Get unique timestamps
    unique_timestamps = sorted(combined_df['timestamp'].unique())
    print(f"Comparing timestamps: {', '.join(unique_timestamps)}")
    
    if plot_type == 'bar':
        # For bar plots, use timestamp as part of the configuration to create separate bars
        for timestamp in unique_timestamps:
            timestamp_df = combined_df[combined_df['timestamp'] == timestamp]
            
            # Create a bar plot for this timestamp with a timestamp label
            create_bar_plot(
                timestamp_df,
                x_column,
                y_column,
                config_columns,
                title=title,
                output_file=output_file,
                sort_bars=sort_bars,
                fig_size=fig_size,
                timestamp_label=timestamp
            )
    
    elif plot_type == 'grouped':
        # For grouped bar plots, use timestamp as part of the configuration to create separate bars
        if group_column is None or group_column not in combined_df.columns:
            print(f"Error: Group column '{group_column}' not found for grouped bar plot. Using 'timestamp' as group column.")
            group_column = 'timestamp'
            
        create_grouped_bar_plot(
            combined_df,
            x_column,
            y_column,
            group_column,
            config_columns,
            title=title,
            output_file=output_file,
            fig_size=fig_size
        )
    
    elif plot_type == 'heatmap':
        # For heatmaps, create separate plots for each timestamp
        for timestamp in unique_timestamps:
            timestamp_df = combined_df[combined_df['timestamp'] == timestamp]
            
            # Create a heatmap for this timestamp
            create_heatmap(
                timestamp_df,
                x_column,
                y_column,
                config_columns[0] if config_columns else 'pgd_size',
                title=f"{title} - {timestamp}" if title else None,
                output_file=output_file.replace('.png', f'_{timestamp.replace(" ", "_").replace(":", "")}.png') if output_file else None,
                fig_size=fig_size
            )

def interactive_timestamp_selection(timestamp_files, experiment_names):
    """
    Interactive selection of timestamp(s) to visualize
    
    Args:
        timestamp_files: Dictionary mapping timestamps to file paths
        experiment_names: Dictionary mapping timestamps to experiment names
        
    Returns:
        List of selected timestamp keys
    """
    print("\n=== Available Timestamp Experiments ===")
    timestamps = list(timestamp_files.keys())
    
    for i, timestamp in enumerate(timestamps, 1):
        exp_name = experiment_names.get(timestamp, "Unknown")
        print(f"{i}. {timestamp} - {exp_name}")
    
    print("\nSelect timestamp(s) to visualize (separated by spaces, e.g., '1 3 5'), or 'all' for all:")
    selection = input().strip()
    
    if selection.lower() == 'all':
        return timestamps
    
    try:
        indices = [int(idx) for idx in selection.split()]
        selected_timestamps = [timestamps[idx-1] for idx in indices if 1 <= idx <= len(timestamps)]
        return selected_timestamps
    except (ValueError, IndexError):
        print("Invalid selection. Using the first timestamp.")
        return [timestamps[0]] if timestamps else []

def interactive_metric_selection(metric_columns):
    """
    Interactive selection of metric(s) to visualize
    
    Args:
        metric_columns: List of available metric columns
        
    Returns:
        List of selected metric columns
    """
    print("\n=== Y-Axis Metric Selection ===")
    print("You can select multiple metrics to create multiple plots")
    for i, col in enumerate(metric_columns, 1):
        print(f"{i}. {col}")
    
    print("\nSelect metric(s) to visualize (separated by spaces, e.g., '1 3 5'):")
    selection = input().strip()
    
    try:
        indices = [int(idx) for idx in selection.split()]
        selected_metrics = [metric_columns[idx-1] for idx in indices if 1 <= idx <= len(metric_columns)]
        if not selected_metrics:
            print("Invalid selection. Using the first metric.")
            return [metric_columns[0]] if metric_columns else []
        return selected_metrics
    except (ValueError, IndexError):
        print("Invalid selection. Using the first metric.")
        return [metric_columns[0]] if metric_columns else []

def interactive_mode(timestamp_files, experiment_names):
    """
    Run in interactive mode, allowing user to select options
    
    Args:
        timestamp_files: Dictionary mapping timestamps to file paths
        experiment_names: Dictionary mapping timestamps to experiment names
        
    Returns:
        Dictionary with plotting options and selected timestamps
    """
    # Select timestamps
    selected_timestamps = interactive_timestamp_selection(timestamp_files, experiment_names)
    
    if not selected_timestamps:
        print("No timestamps selected. Exiting.")
        return None
    
    # Load the first selected timestamp to get column information
    first_file = timestamp_files[selected_timestamps[0]]
    df = load_data(first_file)
    
    if df.empty:
        print(f"Error loading data from {first_file}. Exiting.")
        return None
    
    # Fill missing TOC values with defaults
    if 'toc_enabled' in df.columns:
        df['toc_enabled'] = df['toc_enabled'].fillna(False)
    if 'toc_size' in df.columns:
        df['toc_size'] = df['toc_size'].fillna(0)
    
    # Define configuration column groups
    pagetable_cols = ['pgd_size', 'pud_size', 'pmd_size', 'pte_size']
    pwc_cols = ['pgd_pwc_entries', 'pud_pwc_entries', 'pmd_pwc_entries']
    toc_cols = ['toc_enabled', 'toc_size']
    all_config_cols = pagetable_cols + pwc_cols + toc_cols
    
    # Get actual columns that exist in the dataframe
    config_cols = [col for col in all_config_cols if col in df.columns]
    
    # Create configuration IDs for all rows
    df['_config_id'] = df.apply(lambda row: generate_config_id(row, config_cols), axis=1)
    
    # Get unique configurations
    unique_configs = df[['_config_id'] + config_cols].drop_duplicates().reset_index(drop=True)
    
    # Sort configurations by page table size, PWC entries, and TOC settings
    sort_cols = [col for col in ['pgd_size', 'pud_size', 'pmd_size', 'pte_size', 
                               'pgd_pwc_entries', 'pud_pwc_entries', 'pmd_pwc_entries',
                               'toc_enabled', 'toc_size'] if col in unique_configs.columns]
    if sort_cols:
        unique_configs = unique_configs.sort_values(by=sort_cols).reset_index(drop=True)
    
    # Create descriptive labels for the unique configurations
    config_labels = []
    for i, row in unique_configs.iterrows():
        config_id = row['_config_id']
        # Create a more user-friendly label
        label_parts = config_id.split("::")
        config_labels.append((i, config_id, " ".join(label_parts)))
    
    # Get metric columns for plotting
    metric_columns = [col for col in df.columns if any(x in col for x in 
                                                  ['hit', 'miss', 'efficiency', 'accesses', 'cost', 'avg'])]
    
    # Sort columns by name for better display
    metric_columns.sort()
    
    # Get unique workload values if available
    workload_values = []
    if 'workload' in df.columns:
        workload_values = sorted(df['workload'].unique())
    
    # Plot type selection
    print("\n=== Plot Type Selection ===")
    print("1. Bar Plot (configurations as separate bars)")
    print("2. Grouped Bar Plot (configurations grouped by a column)")
    print("3. Heatmap (configurations as a matrix)")
    
    while True:
        try:
            plot_type_choice = int(input("Enter your choice (1-3): "))
            if 1 <= plot_type_choice <= 3:
                break
            print("Invalid choice. Please enter a number between 1 and 3.")
        except ValueError:
            print("Invalid input. Please enter a number.")
    
    plot_types = ['bar', 'grouped', 'heatmap']
    plot_type = plot_types[plot_type_choice - 1]
    
    # X-axis selection
    print("\n=== X-Axis Selection ===")
    print("1. Workload")
    print("2. Another column")
    
    while True:
        try:
            x_choice = int(input("Enter your choice (1-2): "))
            if 1 <= x_choice <= 2:
                break
            print("Invalid choice. Please enter a number between 1 and 2.")
        except ValueError:
            print("Invalid input. Please enter a number.")
    
    if x_choice == 1:
        x_column = 'workload'
    else:
        print("\nAvailable columns:")
        available_cols = all_config_cols + [col for col in df.columns if col not in all_config_cols + ['_config_id'] and col != 'workload']
        for i, col in enumerate(available_cols, 1):
            print(f"{i}. {col}")
        
        while True:
            try:
                col_choice = int(input("Enter column number: "))
                if 1 <= col_choice <= len(available_cols):
                    x_column = available_cols[col_choice - 1]
                    break
                print(f"Invalid choice. Please enter a number between 1 and {len(available_cols)}.")
            except ValueError:
                print("Invalid input. Please enter a number.")
    
    # Y-axis (metric) selection - support multiple metrics
    y_columns = interactive_metric_selection(metric_columns)
    
    # For grouped bar plots, select group column
    group_column = None
    if plot_type == 'grouped':
        print("\n=== Group Column Selection ===")
        group_cols = all_config_cols + [col for col in df.columns if col not in all_config_cols + ['_config_id'] and col != 'workload']
        for i, col in enumerate(group_cols, 1):
            print(f"{i}. {col}")
        
        while True:
            try:
                group_choice = int(input(f"Enter your choice (1-{len(group_cols)}): "))
                if 1 <= group_choice <= len(group_cols):
                    group_column = group_cols[group_choice - 1]
                    break
                print(f"Invalid choice. Please enter a number between 1 and {len(group_cols)}.")
            except ValueError:
                print("Invalid input. Please enter a number.")
    
    # Configuration columns selection - Use all config columns by default
    selected_config_columns = all_config_cols

    # Filter selection - Only allow filtering on configurations and workload
    selected_config_ids = []
    selected_workloads = []
    
    # Configuration filtering
    print("\n=== Configuration Filter Selection ===")
    print("Select which configurations to include? (y/[N])")
    filter_choice = input().lower()
    
    if filter_choice == 'y':
        # Show all unique configuration combinations (sorted)
        print("\n=== Available Configuration Combinations ===")
        print("Select which complete configurations to include:")
        
        for i, (idx, config_id, config_label) in enumerate(config_labels, 1):
            print(f"{i}. {config_label}")
        
        print("\nEnter the numbers of configurations to include (separated by spaces), or press Enter for all:")
        filter_input = input().strip()
        
        if filter_input:
            try:
                filter_choices = [int(choice) for choice in filter_input.split()]
                if all(1 <= choice <= len(config_labels) for choice in filter_choices):
                    # Get the selected configuration IDs
                    selected_config_ids = [config_labels[choice - 1][1] for choice in filter_choices]
                else:
                    print("Invalid choices. Including all configurations.")
            except ValueError:
                print("Invalid input. Including all configurations.")
    
    # Workload filtering (if available)
    if workload_values:
        print("\n=== Workload Filter Selection ===")
        print("Select which workloads to include? (y/[N])")
        workload_filter_choice = input().lower()
        
        if workload_filter_choice == 'y':
            print("\nAvailable workloads:")
            for i, val in enumerate(workload_values, 1):
                print(f"{i}. {val}")
            
            print("\nEnter the numbers of workloads to include (separated by spaces), or press Enter for all:")
            filter_input = input().strip()
            
            if filter_input:
                try:
                    filter_choices = [int(choice) for choice in filter_input.split()]
                    if all(1 <= choice <= len(workload_values) for choice in filter_choices):
                        selected_workloads = [workload_values[choice - 1] for choice in filter_choices]
                    else:
                        print("Invalid choices. Including all workloads.")
                except ValueError:
                    print("Invalid input. Including all workloads.")
    
    # Sort option
    print("\n=== Sort Option ===")
    print("Sort bars by y-value? ([Y]/n)")
    sort_choice = input().lower()
    # if no input, default to 'y'
    if not sort_choice:
        sort_choice = 'y'
    sort_bars = sort_choice == 'y'
    
    # Multiple timestamp comparison option
    compare_timestamps = False
    if len(selected_timestamps) > 1:
        print("\n=== Multiple Timestamp Comparison ===")
        print("1. Create separate plots for each timestamp")
        print("2. Create a single comparison plot with all timestamps")
        
        while True:
            try:
                compare_choice = int(input("Enter your choice (1-2): "))
                if 1 <= compare_choice <= 2:
                    compare_timestamps = compare_choice == 2
                    break
                print("Invalid choice. Please enter a number between 1 and 2.")
            except ValueError:
                print("Invalid input. Please enter a number.")
    
    # Output file option
    print("\n=== Output File ===")
    print("Save plots to files? ([Y]/n)")
    save_choice = input().lower()
    # if no input, default to 'y'
    if not save_choice:
        save_choice = 'y'
    
    output_dir = None
    if save_choice == 'y':
        print("Enter output directory (default: 'plots'):")
        output_dir = input().strip()
        if not output_dir:
            output_dir = 'plots'
        
        # Create the directory if it doesn't exist
        os.makedirs(output_dir, exist_ok=True)
    
    # Clean up temporary column
    if '_config_id' in df.columns:
        df = df.drop('_config_id', axis=1)
    
    # Create options dictionary
    options = {
        'selected_timestamps': selected_timestamps,
        'plot_type': plot_type,
        'x_column': x_column,
        'y_columns': y_columns,  # List of columns
        'group_column': group_column,
        'config_columns': selected_config_columns,
        'selected_config_ids': selected_config_ids,  # Configuration filtering
        'selected_workloads': selected_workloads,    # Workload filtering
        'sort_bars': sort_bars,
        'output_dir': output_dir,
        'compare_timestamps': compare_timestamps
    }
    
    return options

def parse_args():
    """Parse command line arguments"""
    parser = argparse.ArgumentParser(description='Visualize timestamp-based memory simulator results')
    parser.add_argument('-d', '--input_dir', type=str, required=True,
                        help='Directory containing timestamp-specific CSV files')
    parser.add_argument('-o', '--output_dir', type=str, default='plots',
                        help='Directory to save the plots')
    parser.add_argument('-t', '--plot_type', type=str, choices=['bar', 'grouped', 'heatmap'], default='bar',
                        help='Type of plot to generate')
    parser.add_argument('-x', '--x_column', type=str, default='workload',
                        help='Column to use for x-axis')
    parser.add_argument('-y', '--y_columns', type=str, nargs='+',
                        default=['l1_tlb_hit_percentage'],
                        help='Column(s) to use for y-axis (the statistic(s) to visualize)')
    parser.add_argument('-g', '--group_column', type=str, default='toc_enabled',
                        help='Column to use for grouping (only for grouped bar plots)')
    parser.add_argument('-s', '--sort', action='store_true',
                        help='Sort bars by y-value')
    parser.add_argument('--timestamp', type=str, nargs='+',
                        help='Specific timestamp(s) to visualize (format: YYYYMMDD_HHMMSS)')
    parser.add_argument('--list_timestamps', action='store_true',
                        help='List available timestamp experiments and exit')
    parser.add_argument('--interactive', action='store_true',
                        help='Enable interactive mode for selecting plotting options')
    parser.add_argument('--compare', action='store_true',
                        help='Compare multiple timestamps in a single plot')
    
    return parser.parse_args()

def create_output_path(output_dir, timestamp, plot_type, x_column, y_column, is_comparison=False):
    """
    Create an appropriate output path for the plot file
    
    Args:
        output_dir: Base output directory
        timestamp: Timestamp being plotted
        plot_type: Type of plot
        x_column: X-axis column
        y_column: Y-axis column
        is_comparison: Whether this is a comparison plot
        
    Returns:
        Path to save the plot file
    """
    # Format timestamp for filename
    if isinstance(timestamp, list):
        # For multiple timestamps, use 'comparison' in the filename
        ts_filename = "comparison"
    else:
        ts_filename = timestamp.replace('-', '').replace(' ', '_').replace(':', '')
    
    # Create a subdirectory for this timestamp if not a comparison
    if not is_comparison and not isinstance(timestamp, list):
        timestamp_dir = os.path.join(output_dir, ts_filename)
        os.makedirs(timestamp_dir, exist_ok=True)
        base_filename = f"{plot_type}_{x_column}_{y_column}.png"
        output_file = os.path.join(timestamp_dir, base_filename)
    else:
        # For comparisons or if timestamp is not used, save directly to output_dir
        base_filename = f"{plot_type}_{ts_filename}_{x_column}_{y_column}.png"
        output_file = os.path.join(output_dir, base_filename)
    
    return output_file

def main():
    """Main function"""
    args = parse_args()
    
    # Find timestamp-specific CSV files
    timestamp_files = find_timestamp_csvs(args.input_dir)
    
    if not timestamp_files:
        print(f"No timestamp-specific CSV files found in {args.input_dir}")
        print("Expected file pattern: experiment_YYYYMMDD_HHMMSS.csv")
        return
    
    # Get experiment names for each timestamp
    experiment_names = list_experiment_names(timestamp_files)
    
    # If requested, list available timestamps and exit
    if args.list_timestamps:
        print("\nAvailable timestamp experiments:")
        for i, (timestamp, file_path) in enumerate(timestamp_files.items(), 1):
            exp_name = experiment_names.get(timestamp, "Unknown")
            print(f"{i}. {timestamp} - {exp_name} ({file_path})")
        return
    
    # Define default configuration columns
    config_columns = ['pgd_size', 'pud_size', 'pmd_size', 'pte_size', 
                     'pgd_pwc_entries', 'pud_pwc_entries', 'pmd_pwc_entries', 
                     'toc_enabled', 'toc_size']
    
    # If interactive mode is enabled, get options from user
    if args.interactive:
        options = interactive_mode(timestamp_files, experiment_names)
        if not options:
            return
        
        selected_timestamps = options['selected_timestamps']
        plot_type = options['plot_type']
        x_column = options['x_column']
        y_columns = options['y_columns']
        group_column = options['group_column']
        config_columns = options['config_columns']
        selected_config_ids = options.get('selected_config_ids', [])
        other_filters = options.get('other_filters', {})
        sort_bars = options['sort_bars']
        output_dir = options['output_dir']
        compare_timestamps = options['compare_timestamps']
    else:
        # Use command line arguments
        # Select timestamps
        if args.timestamp:
            # Find matching timestamps
            selected_timestamps = []
            for timestamp in timestamp_files.keys():
                # Extract the raw timestamp part for comparison
                timestamp_raw = timestamp.replace('-', '').replace(' ', '_').replace(':', '')
                if any(t in timestamp_raw for t in args.timestamp):
                    selected_timestamps.append(timestamp)
        else:
            # Use all timestamps
            selected_timestamps = list(timestamp_files.keys())
        
        plot_type = args.plot_type
        x_column = args.x_column
        y_columns = args.y_columns
        group_column = args.group_column
        selected_config_ids = []  # No configuration filtering in command-line mode
        other_filters = {}
        sort_bars = args.sort
        output_dir = args.output_dir
        compare_timestamps = args.compare
    
    # Create output directory if specified
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
    
    # Function to apply all filters to a dataframe
    def apply_all_filters(df):
        # Apply configuration filtering if any configs were selected
        if selected_config_ids:
            df = filter_data(df, selected_config_ids)
        
        # Apply other column filters
        for col, values in other_filters.items():
            if col in df.columns and values:
                df = df[df[col].isin(values)]
        
        return df
    
    # If comparing multiple timestamps, load all data and create comparison plots
    if compare_timestamps and len(selected_timestamps) > 1:
        print(f"\nCreating comparison plots for {len(selected_timestamps)} timestamps")
        
        # Load data from all selected timestamps
        dataframes = []
        for timestamp in selected_timestamps:
            file_path = timestamp_files[timestamp]
            exp_name = experiment_names.get(timestamp, "Unknown")
            
            print(f"Loading data from: {timestamp} - {exp_name}")
            df = load_data(file_path)
            
            if not df.empty:
                # Fill missing TOC values with defaults
                if 'toc_enabled' in df.columns:
                    df['toc_enabled'] = df['toc_enabled'].fillna(False)
                if 'toc_size' in df.columns:
                    df['toc_size'] = df['toc_size'].fillna(0)
                
                # Apply all filters
                filtered_df = apply_all_filters(df)
                dataframes.append(filtered_df)
            else:
                dataframes.append(pd.DataFrame())
        
        # Combine dataframes
        combined_df = combine_dataframes(dataframes, selected_timestamps)
        
        if combined_df.empty:
            print("No data to plot after combining dataframes")
            return
        
        # Process each selected y-column (metric)
        for y_column in y_columns:
            if y_column not in combined_df.columns:
                print(f"Warning: Column {y_column} not found in data, skipping")
                continue
            
            print(f"Creating comparison plot for metric: {y_column}")
            
            # Create output filename for comparison plot
            if output_dir:
                output_file = create_output_path(output_dir, selected_timestamps, plot_type, x_column, y_column, is_comparison=True)
            else:
                output_file = None
            
            # Create title with experiment names and metric
            exp_names_str = ", ".join([experiment_names.get(ts, "Unknown") for ts in selected_timestamps])
            title = f"Comparison: {exp_names_str} - {y_column.replace('_', ' ').title()} by {x_column.replace('_', ' ').title()}"
            
            # Create comparison plot
            create_comparison_plot(
                combined_df,
                x_column,
                y_column,
                config_columns,
                plot_type=plot_type,
                group_column=group_column,
                title=title,
                output_file=output_file,
                sort_bars=sort_bars
            )
    
    else:
        # Process each selected timestamp separately
        for timestamp in selected_timestamps:
            file_path = timestamp_files[timestamp]
            exp_name = experiment_names.get(timestamp, "Unknown")
            
            print(f"\nProcessing: {timestamp} - {exp_name}")
            
            # Load data
            df = load_data(file_path)
            if df.empty:
                continue
            
            # Fill missing TOC values with defaults
            if 'toc_enabled' in df.columns:
                df['toc_enabled'] = df['toc_enabled'].fillna(False)
            if 'toc_size' in df.columns:
                df['toc_size'] = df['toc_size'].fillna(0)
            
            # Apply all filters
            filtered_df = apply_all_filters(df)
            
            # Process each selected y-column (metric)
            for y_column in y_columns:
                if y_column not in filtered_df.columns:
                    print(f"Warning: Column {y_column} not found in data, skipping")
                    continue
                
                print(f"Creating plot for metric: {y_column}")
                
                # Create output filename with timestamp subdirectory
                if output_dir:
                    output_file = create_output_path(output_dir, timestamp, plot_type, x_column, y_column)
                else:
                    output_file = None
                
                # Create title with timestamp, experiment name, and metric
                title = f"{exp_name} - {timestamp} - {y_column.replace('_', ' ').title()} by {x_column.replace('_', ' ').title()}"
                
                # Create plot based on selected type
                if plot_type == 'bar':
                    create_bar_plot(
                        filtered_df,
                        x_column,
                        y_column,
                        config_columns,
                        title=title,
                        output_file=output_file,
                        sort_bars=sort_bars
                    )
                elif plot_type == 'grouped':
                    create_grouped_bar_plot(
                        filtered_df,
                        x_column,
                        y_column,
                        group_column,
                        config_columns,
                        title=title,
                        output_file=output_file
                    )
                elif plot_type == 'heatmap':
                    create_heatmap(
                        filtered_df,
                        x_column,
                        y_column,
                        config_columns[0] if config_columns else 'pgd_size',
                        title=title,
                        output_file=output_file
                    )
if __name__ == "__main__":
    main()